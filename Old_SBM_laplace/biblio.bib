@article{Ambroise2009,
abstract = {Our concern is selecting the concentration matrix's nonzero coefficients for a sparse Gaussian graphical model in a high-dimensional setting. This corresponds to estimating the graph of conditional dependencies between the variables. We describe a novel framework taking into account a latent structure on the concentration matrix. This latent structure is used to drive a penalty matrix and thus to recover a graphical model with a constrained topology. Our method uses an ell1 penalized likelihood criterion. Inference of the graph of conditional dependencies between the variates and of the hidden variables is performed simultaneously in an iterative textscem-like algorithm. The performances of our method is illustrated on synthetic as well as real data, the latter concerning breast cancer.},
archivePrefix = {arXiv},
arxivId = {arXiv:0810.3177v1},
author = {Ambroise, Christophe and Chiquet, Julien and Matias, Catherine},
doi = {10.1214/08-EJS314},
eprint = {arXiv:0810.3177v1},
file = {:home/donnet/WORK{\_}ALL/RECHERCHE/TRAVAUX{\_}RECHERCHE/Audrey-Julien-Florence/SBM{\_}laplace{\_}prior/biblio/ambroise{\_}chiquet{\_}matias.pdf:pdf},
issn = {19357524},
journal = {Electronic Journal of Statistics},
keywords = {Em algorithm,Gaussian graphical model,L1-penalization,Mixture model,Model selection,Variational inference},
pages = {205--238},
title = {{Inferring sparse gaussian graphical models with latent structure}},
volume = {3},
year = {2009}
}


@article{Marlin2009,
abstract = {Recent work has shown that one can learn the structure of Gaussian Graphical Models by imposing an L1 penalty on the precision matrix, and then using efficient convex opti- mization methods to find the penalized max- imum likelihood estimate. This is similar to performing MAP estimation with a prior that prefers sparse graphs. In this paper, we use the stochastic block model as a prior. This prefer graphs that are blockwise sparse, but unlike previous work, it does not require that the blocks or groups be specified a priori. The resulting problem is no longer convex, but we devise an efficient variational Bayes algo- rithm to solve it. We show that our method has better test set likelihood on two differ- ent datasets (motion capture and gene ex- pression) compared to independent L1, and can match the performance of group L1 us- ing manually created groups. 1.},
author = {Marlin, Benjamin M. and Murphy, Kevin P.},
doi = {10.1145/1553374.1553465},
file = {:home/donnet/WORK{\_}ALL/RECHERCHE/TRAVAUX{\_}RECHERCHE/Audrey-Julien-Florence/SBM{\_}laplace{\_}prior/biblio/MarlinMurphyICML09.pdf:pdf},
pages = {1--8},
title = {{Sparse Gaussian graphical models with unknown block structure}},
year = {2009}
}


@article{Sun2015,
abstract = {Learning the structure of a graphical model is a fundamental problem and it is used extensively to infer the relationship between random variables. In many real world applications, we usually have some prior knowledge about the underlying graph structure, such as degree distribution and block structure. In this paper, we propose a novel generative model for describing the block structure in general exponential families, and optimize it by an Expectation-Maximization(EM) algorithm with variational Bayes. Experimental results show that our method performs well on both synthetic and real data. Furthermore, our method can predict overlapping block structure of a graphical model in general exponential families .},
author = {Sun, Siqi and Wang, Hai},
file = {:home/donnet/WORK{\_}ALL/RECHERCHE/TRAVAUX{\_}RECHERCHE/Audrey-Julien-Florence/SBM{\_}laplace{\_}prior/biblio/sun15.pdf:pdf},
journal = {Proceedings of the 18th International Conference on Artifical Intelligence and Statistics (AISTATS) International Conference on Machine Learning - ICML '09},
title = {{Inferring Block Structure of Graphical Models in Exponential Families}},
volume = {38},
year = {2015}
}
